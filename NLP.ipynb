{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1b2c3d4",
      "metadata": {
        "id": "a1b2c3d4"
      },
      "source": [
        "# Détection de Sarcasme - Analyse NLP\n",
        "Ce notebook explore la classification binaire de titres sarcastiques vs non-sarcastiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b95ae060",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b95ae060",
        "outputId": "f4a141e2-e461-4e47-c6e0-acd006fbb0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shariphthapa/sarcasm-json-datasets?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.59M/1.59M [00:00<00:00, 40.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/shariphthapa/sarcasm-json-datasets/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"shariphthapa/sarcasm-json-datasets\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8af4a007",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "8af4a007",
        "outputId": "706921c3-83f5-4e5f-e0d9-dc2d5603c416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded /root/.cache/kagglehub/datasets/shariphthapa/sarcasm-json-datasets/versions/1/Sarcasm.json -> shape (26709, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        article_link  \\\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
              "2  https://local.theonion.com/mom-starting-to-fea...   \n",
              "3  https://politics.theonion.com/boehner-just-wan...   \n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
              "\n",
              "                                            headline  is_sarcastic  \n",
              "0  former versace store clerk sues over secret 'b...             0  \n",
              "1  the 'roseanne' revival catches up to our thorn...             0  \n",
              "2  mom starting to fear son's web series closest ...             1  \n",
              "3  boehner just wants wife to listen, not come up...             1  \n",
              "4  j.k. rowling wishes snape happy birthday in th...             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e59b3782-9fd8-4228-86be-96286efbdf9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e59b3782-9fd8-4228-86be-96286efbdf9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e59b3782-9fd8-4228-86be-96286efbdf9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e59b3782-9fd8-4228-86be-96286efbdf9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c3198f86-ab38-4029-934c-29ac5c29b937\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3198f86-ab38-4029-934c-29ac5c29b937')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c3198f86-ab38-4029-934c-29ac5c29b937 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26709,\n  \"fields\": [\n    {\n      \"column\": \"article_link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26708,\n        \"samples\": [\n          \"https://www.theonion.com/isis-recruiter-excited-to-be-talking-to-popular-high-sc-1819579508\",\n          \"https://www.huffingtonpost.com/entry/jimmy-fallon-could-barely-keep-it-together-during-this-cardi-b-interview_us_5a3c01aae4b06d1621b2de98\",\n          \"https://www.huffingtonpost.com/entry/4-ways-to-support-farmtos_b_5906452.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26602,\n        \"samples\": [\n          \"departing employee not quite important enough for send-off\",\n          \"college student still managing to look like asshole in picture of village he helped build\",\n          \"fun sticker placed on child's ventilator\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_sarcastic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "candidates = [\n",
        "    \"Sarcasm.json\",\n",
        "    os.path.join(path, \"Sarcasm.json\") if \"path\" in globals() else None,\n",
        "    os.path.join(path, \"Sarcasm_Headlines_Dataset.json\") if \"path\" in globals() else None,\n",
        "]\n",
        "file_path = next((p for p in candidates if p and os.path.exists(p)), \"Sarcasm.json\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_json(file_path, lines=True)\n",
        "except ValueError:\n",
        "    df = pd.read_json(file_path)\n",
        "\n",
        "print(f\"Loaded {file_path} -> shape {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5f6g7h8",
      "metadata": {
        "id": "e5f6g7h8"
      },
      "source": [
        "## Exploration et nettoyage des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2f3a050e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f3a050e",
        "outputId": "80903176-706b-45b1-d601-2c47ea532c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns after dropping article_link: ['headline', 'is_sarcastic']\n",
            "\n",
            "Dataset shape: (26709, 2)\n",
            "\n",
            "First few rows:\n",
            "                                            headline  is_sarcastic\n",
            "0  former versace store clerk sues over secret 'b...             0\n",
            "1  the 'roseanne' revival catches up to our thorn...             0\n",
            "2  mom starting to fear son's web series closest ...             1\n",
            "3  boehner just wants wife to listen, not come up...             1\n",
            "4  j.k. rowling wishes snape happy birthday in th...             0\n",
            "\n",
            "Target distribution (is_sarcastic):\n",
            "is_sarcastic\n",
            "0    14985\n",
            "1    11724\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_clean = df.drop(columns=['article_link'])\n",
        "print(\"Columns after dropping article_link:\", df_clean.columns.tolist())\n",
        "print(\"\\nDataset shape:\", df_clean.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df_clean.head())\n",
        "print(\"\\nTarget distribution (is_sarcastic):\")\n",
        "print(df_clean['is_sarcastic'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4246dffc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4246dffc",
        "outputId": "60de923b-e4fe-4fb3-e900-26fd95a3b635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i9j0k1l2",
      "metadata": {
        "id": "i9j0k1l2"
      },
      "source": [
        "## Prétraitement textuel avec NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "710047d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "710047d9",
        "outputId": "cc4bcae6-128c-4669-c826-0cce4af8f3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking and downloading NLTK resources...\n",
            "  Downloading punkt...\n",
            "  ✓ punkt downloaded\n",
            "  Downloading punkt_tab...\n",
            "  ✓ punkt_tab downloaded\n",
            "  Downloading stopwords...\n",
            "  ✓ stopwords downloaded\n",
            "NLTK resources check complete!\n",
            "\n",
            "Loaded 198 stop words\n",
            "Sample stop words: [\"hasn't\", 'mightn', 'itself', 'shouldn', 'what', 'during', 'until', 'themselves', 'ours', 're']\n",
            "\n",
            "Preprocessing headlines...\n",
            "Sample preprocessed headlines:\n",
            "  Original: former versace store clerk sues over secret 'black code' for minority shoppers\n",
            "  Tokens: ['former', 'versace', 'store', 'clerk', 'sues', 'secret', 'black', 'code', 'minority', 'shoppers']\n",
            "\n",
            "  Original: the 'roseanne' revival catches up to our thorny political mood, for better and worse\n",
            "  Tokens: ['roseanne', 'revival', 'catches', 'thorny', 'political', 'mood', 'better', 'worse']\n",
            "\n",
            "  Original: mom starting to fear son's web series closest thing she will have to grandchild\n",
            "  Tokens: ['mom', 'starting', 'fear', 'son', 'web', 'series', 'closest', 'thing', 'grandchild']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "\n",
        "print(\"Checking and downloading NLTK resources...\")\n",
        "resources_to_download = ['punkt', 'punkt_tab', 'stopwords']\n",
        "\n",
        "for resource in resources_to_download:\n",
        "    try:\n",
        "        if resource == 'stopwords':\n",
        "            stopwords.words('english')\n",
        "        else:\n",
        "            nltk.data.find(f'tokenizers/{resource}')\n",
        "        print(f\"  ✓ {resource} already available\")\n",
        "    except LookupError:\n",
        "        try:\n",
        "            print(f\"  Downloading {resource}...\")\n",
        "            nltk.download(resource, quiet=True)\n",
        "            print(f\"  ✓ {resource} downloaded\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠ Could not download {resource}: {e}\")\n",
        "\n",
        "print(\"NLTK resources check complete!\")\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(f\"\\nLoaded {len(stop_words)} stop words\")\n",
        "print(f\"Sample stop words: {list(stop_words)[:10]}\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    text = text.lower()\n",
        "    text = re.sub(f'[{re.escape(string.punctuation)}]', ' ', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t.strip() and t not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "print(\"\\nPreprocessing headlines...\")\n",
        "df_clean['headline_tokens'] = df_clean['headline'].apply(preprocess_text)\n",
        "print(\"Sample preprocessed headlines:\")\n",
        "for i in range(3):\n",
        "    print(f\"  Original: {df_clean['headline'].iloc[i]}\")\n",
        "    print(f\"  Tokens: {df_clean['headline_tokens'].iloc[i]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m3n4o5p6",
      "metadata": {
        "id": "m3n4o5p6"
      },
      "source": [
        "## Tokenization et padding avec Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3cf13081",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cf13081",
        "outputId": "a2286c16-074c-4133-df5e-c7a1c691f63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer fitted on 26709 headlines\n",
            "Total unique words (vocab size): 25220\n",
            "OOV token index: 1\n",
            "\n",
            "Top 20 most common words:\n",
            "  <OOV>: 1\n",
            "  trump: 2\n",
            "  new: 3\n",
            "  man: 4\n",
            "  year: 5\n",
            "  one: 6\n",
            "  report: 7\n",
            "  area: 8\n",
            "  woman: 9\n",
            "  donald: 10\n",
            "  day: 11\n",
            "  u: 12\n",
            "  says: 13\n",
            "  time: 14\n",
            "  first: 15\n",
            "  obama: 16\n",
            "  like: 17\n",
            "  women: 18\n",
            "  people: 19\n",
            "  get: 20\n",
            "\n",
            "Max headline length: 27\n",
            "Padded sequences shape: (26709, 27)\n",
            "First 3 padded sequences shape: (3, 27)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer_sarcasm = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "\n",
        "headline_strings = [' '.join(tokens) for tokens in df_clean['headline_tokens']]\n",
        "tokenizer_sarcasm.fit_on_texts(headline_strings)\n",
        "\n",
        "print(f\"Tokenizer fitted on {len(headline_strings)} headlines\")\n",
        "print(f\"Total unique words (vocab size): {len(tokenizer_sarcasm.word_index)}\")\n",
        "print(f\"OOV token index: {tokenizer_sarcasm.word_index.get('<OOV>')}\")\n",
        "print(f\"\\nTop 20 most common words:\")\n",
        "sorted_words = sorted(tokenizer_sarcasm.word_index.items(), key=lambda x: x[1])[:20]\n",
        "for word, idx in sorted_words:\n",
        "    print(f\"  {word}: {idx}\")\n",
        "\n",
        "sequences_sarcasm = tokenizer_sarcasm.texts_to_sequences(headline_strings)\n",
        "\n",
        "max_len = max(len(seq) for seq in sequences_sarcasm) if sequences_sarcasm else 100\n",
        "max_len = min(max_len, 100)\n",
        "padded_sarcasm = pad_sequences(sequences_sarcasm, maxlen=max_len, padding='post')\n",
        "\n",
        "print(f\"\\nMax headline length: {max_len}\")\n",
        "print(f\"Padded sequences shape: {padded_sarcasm.shape}\")\n",
        "print(f\"First 3 padded sequences shape: {padded_sarcasm[:3].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q7r8s9t0",
      "metadata": {
        "id": "q7r8s9t0"
      },
      "source": [
        "## Préparation des features et target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1e7fd309",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e7fd309",
        "outputId": "23022941-674e-4a20-8646-63a060cdb774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape (X): (26709, 27)\n",
            "Target shape (y): (26709,)\n",
            "\n",
            "Target distribution:\n",
            "  Sarcastic (1): 11724 (43.9%)\n",
            "  Non-sarcastic (0): 14985 (56.1%)\n",
            "\n",
            "Model dataset shape: (26709, 28)\n",
            "First few rows:\n",
            "    tok_0   tok_1   tok_2   tok_3   tok_4   tok_5   tok_6   tok_7   tok_8  \\\n",
            "0   220.0     1.0   543.0  3034.0  2201.0   273.0    35.0  1995.0  2498.0   \n",
            "1     1.0  3262.0  2675.0     1.0   309.0  2829.0   164.0   892.0     0.0   \n",
            "2    58.0   749.0   727.0   144.0  1996.0   485.0  4567.0   129.0     1.0   \n",
            "3  1240.0   138.0   260.0  1592.0   224.0  2830.0  1294.0     1.0   790.0   \n",
            "4   669.0   597.0  3784.0   819.0     1.0   463.0   464.0  1163.0    36.0   \n",
            "\n",
            "   tok_9  ...  tok_18  tok_19  tok_20  tok_21  tok_22  tok_23  tok_24  tok_25  \\\n",
            "0    1.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "1    0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "2    0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "3    0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "4    0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
            "\n",
            "   tok_26  is_sarcastic  \n",
            "0     0.0             0  \n",
            "1     0.0             0  \n",
            "2     0.0             1  \n",
            "3     0.0             1  \n",
            "4     0.0             0  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ],
      "source": [
        "X_sarcasm = padded_sarcasm.astype('float32')\n",
        "y_sarcasm = df_clean['is_sarcastic'].values.astype('int32')\n",
        "\n",
        "print(f\"Features shape (X): {X_sarcasm.shape}\")\n",
        "print(f\"Target shape (y): {y_sarcasm.shape}\")\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(f\"  Sarcastic (1): {(y_sarcasm == 1).sum()} ({100 * (y_sarcasm == 1).sum() / len(y_sarcasm):.1f}%)\")\n",
        "print(f\"  Non-sarcastic (0): {(y_sarcasm == 0).sum()} ({100 * (y_sarcasm == 0).sum() / len(y_sarcasm):.1f}%)\")\n",
        "\n",
        "feature_cols = [f'tok_{i}' for i in range(X_sarcasm.shape[1])]\n",
        "X_df = pd.DataFrame(X_sarcasm, columns=feature_cols)\n",
        "df_model = X_df.copy()\n",
        "df_model['is_sarcastic'] = y_sarcasm\n",
        "\n",
        "print(f\"\\nModel dataset shape: {df_model.shape}\")\n",
        "print(f\"First few rows:\")\n",
        "print(df_model.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u1v2w3x4",
      "metadata": {
        "id": "u1v2w3x4"
      },
      "source": [
        "## Régression logistique baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5d75f78d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d75f78d",
        "outputId": "49bbf1e7-a17c-40ca-8faa-7be3ec87c5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 18696 samples\n",
            "Test set: 8013 samples\n",
            "\n",
            "Training logistic regression...\n",
            "Training complete!\n",
            "\n",
            "============================================================\n",
            "MODEL EVALUATION\n",
            "============================================================\n",
            "Accuracy: 0.5657\n",
            "ROC AUC: 0.5623\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3074 1422]\n",
            " [2058 1459]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Non-Sarcastic       0.60      0.68      0.64      4496\n",
            "    Sarcastic       0.51      0.41      0.46      3517\n",
            "\n",
            "     accuracy                           0.57      8013\n",
            "    macro avg       0.55      0.55      0.55      8013\n",
            " weighted avg       0.56      0.57      0.56      8013\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_sarcasm, y_sarcasm, test_size=0.3, stratify=y_sarcasm, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "clf_sarcasm = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced', solver='lbfgs')\n",
        "print(\"\\nTraining logistic regression...\")\n",
        "clf_sarcasm.fit(X_train, y_train)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "y_pred = clf_sarcasm.predict(X_test)\n",
        "y_pred_proba = clf_sarcasm.predict_proba(X_test)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Non-Sarcastic', 'Sarcastic']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c2a8dc8"
      },
      "source": [
        "### Commentaires sur la Régression Logistique Baseline\n",
        "\n",
        "*   **Précision (Accuracy)** : Avec 56.57%, le modèle n'est que légèrement meilleur qu'une classification aléatoire (qui serait de 50%). Cela indique que le modèle a du mal à distinguer correctement les phrases sarcastiques des non-sarcastiques.\n",
        "*   **ROC AUC** : Un score de 0.5623 est également assez bas, suggérant que le modèle a une faible capacité à séparer les classes positives (sarcastiques) des négatives (non-sarcastiques). Un score de 0.5 signifie qu'il ne fait pas mieux que le hasard.\n",
        "*   **Matrice de Confusion** :\n",
        "    *   **Vrais Positifs (TP)** : 1459 phrases sarcastiques ont été correctement identifiées comme sarcastiques.\n",
        "    *   **Faux Négatifs (FN)** : 2058 phrases sarcastiques ont été incorrectement classées comme non-sarcastiques (le modèle les a manquées).\n",
        "    *   **Vrais Négatifs (TN)** : 3074 phrases non-sarcastiques ont été correctement identifiées comme non-sarcastiques.\n",
        "    *   **Faux Positifs (FP)** : 1422 phrases non-sarcastiques ont été incorrectement classées comme sarcastiques (le modèle a fait une fausse alarme).\n",
        "*   **Rapport de Classification** :\n",
        "    *   **Classe 'Non-Sarcastic' (0)** : Le modèle a une précision de 0.60 (60% des prédictions 'non-sarcastique' étaient correctes) et un rappel de 0.68 (68% des vrais 'non-sarcastiques' ont été trouvés).\n",
        "    *   **Classe 'Sarcastic' (1)** : La précision est plus faible à 0.51 (seulement 51% des prédictions 'sarcastique' étaient correctes), et le rappel est encore plus bas à 0.41 (seulement 41% des vrais 'sarcastiques' ont été trouvés). Cela montre que le modèle a beaucoup de mal à identifier la sarcasme.\n",
        "\n",
        "En résumé, ce modèle de régression logistique de base offre des performances médiocres. Il a particulièrement du mal à identifier les titres sarcastiques, ce qui est indiqué par un faible rappel pour cette classe."
      ],
      "id": "0c2a8dc8"
    },
    {
      "cell_type": "markdown",
      "id": "y5z6a7b8",
      "metadata": {
        "id": "y5z6a7b8"
      },
      "source": [
        "## Approche avec Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "947094ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "947094ca",
        "outputId": "9a6f5146-3ca0-4157-9b54-cfdcb11654b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EMBEDDING LAYER APPROACH\n",
            "======================================================================\n",
            "\n",
            "Embedding Configuration:\n",
            "  Vocabulary size: 5001\n",
            "  Embedding dimension: 64\n",
            "  Input sequence length: 27\n",
            "\n",
            "Converting sequences to embeddings...\n",
            "Embedded data shape: (26709, 27, 64)\n",
            "Flattened embeddings shape (average pooling): (26709, 64)\n",
            "\n",
            "Train set (embedded): 18696 samples\n",
            "Test set (embedded): 8013 samples\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"EMBEDDING LAYER APPROACH\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "embedding_dim = 64\n",
        "vocab_size = 5000 + 1\n",
        "\n",
        "embedding_model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len)\n",
        "])\n",
        "\n",
        "print(f\"\\nEmbedding Configuration:\")\n",
        "print(f\"  Vocabulary size: {vocab_size}\")\n",
        "print(f\"  Embedding dimension: {embedding_dim}\")\n",
        "print(f\"  Input sequence length: {max_len}\")\n",
        "\n",
        "print(\"\\nConverting sequences to embeddings...\")\n",
        "X_embedded = embedding_model.predict(padded_sarcasm, verbose=0)\n",
        "print(f\"Embedded data shape: {X_embedded.shape}\")\n",
        "\n",
        "X_embedded_flat = X_embedded.mean(axis=1)\n",
        "print(f\"Flattened embeddings shape (average pooling): {X_embedded_flat.shape}\")\n",
        "\n",
        "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(\n",
        "    X_embedded_flat, y_sarcasm, test_size=0.3, stratify=y_sarcasm, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain set (embedded): {X_train_emb.shape[0]} samples\")\n",
        "print(f\"Test set (embedded): {X_test_emb.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d0e1f2",
      "metadata": {
        "id": "c9d0e1f2"
      },
      "source": [
        "## Régression logistique sur embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5987f7b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5987f7b3",
        "outputId": "22989182-1d76-4392-c749-5ade62c795b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "LOGISTIC REGRESSION ON EMBEDDED DATA\n",
            "======================================================================\n",
            "\n",
            "Training logistic regression on embeddings...\n",
            "Training complete!\n",
            "\n",
            "============================================================\n",
            "EMBEDDED MODEL EVALUATION\n",
            "============================================================\n",
            "Accuracy: 0.5547\n",
            "ROC AUC: 0.5909\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2540 1956]\n",
            " [1612 1905]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Non-Sarcastic       0.61      0.56      0.59      4496\n",
            "    Sarcastic       0.49      0.54      0.52      3517\n",
            "\n",
            "     accuracy                           0.55      8013\n",
            "    macro avg       0.55      0.55      0.55      8013\n",
            " weighted avg       0.56      0.55      0.56      8013\n",
            "\n",
            "\n",
            "============================================================\n",
            "COMPARISON: ORIGINAL vs EMBEDDED\n",
            "============================================================\n",
            "Original Accuracy:  0.5657\n",
            "Embedded Accuracy:  0.5547\n",
            "Improvement:        -1.10%\n",
            "\n",
            "Original ROC AUC:   0.5623\n",
            "Embedded ROC AUC:   0.5909\n",
            "Improvement:        +0.0285\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LOGISTIC REGRESSION ON EMBEDDED DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "clf_embedded = LogisticRegression(max_iter=5000, random_state=42, class_weight='balanced', solver='lbfgs')\n",
        "print(\"\\nTraining logistic regression on embeddings...\")\n",
        "clf_embedded.fit(X_train_emb, y_train_emb)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "y_pred_emb = clf_embedded.predict(X_test_emb)\n",
        "y_pred_proba_emb = clf_embedded.predict_proba(X_test_emb)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EMBEDDED MODEL EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "acc_embedded = accuracy_score(y_test_emb, y_pred_emb)\n",
        "roc_embedded = roc_auc_score(y_test_emb, y_pred_proba_emb[:, 1])\n",
        "\n",
        "print(f\"Accuracy: {acc_embedded:.4f}\")\n",
        "print(f\"ROC AUC: {roc_embedded:.4f}\")\n",
        "print(f\"\\nConfusion Matrix:\\n{confusion_matrix(y_test_emb, y_pred_emb)}\")\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_emb, y_pred_emb, target_names=['Non-Sarcastic', 'Sarcastic']))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON: ORIGINAL vs EMBEDDED\")\n",
        "print(\"=\"*60)\n",
        "acc_original = accuracy_score(y_test, y_pred)\n",
        "roc_original = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
        "\n",
        "print(f\"Original Accuracy:  {acc_original:.4f}\")\n",
        "print(f\"Embedded Accuracy:  {acc_embedded:.4f}\")\n",
        "print(f\"Improvement:        {(acc_embedded - acc_original)*100:+.2f}%\")\n",
        "print(f\"\\nOriginal ROC AUC:   {roc_original:.4f}\")\n",
        "print(f\"Embedded ROC AUC:   {roc_embedded:.4f}\")\n",
        "print(f\"Improvement:        {(roc_embedded - roc_original):+.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c7d79e1"
      },
      "source": [
        "## Performance du modele\n",
        "\n",
        "\n",
        "\n",
        "*   **Précision (Accuracy)**: La régression logistique sur les données encodées (0.5547) a montré une légère baisse de précision par rapport au modèle original (0.5657), soit une diminution de 1.10%.\n",
        "*   **ROC AUC**: En revanche, l'aire sous la courbe ROC (ROC AUC) a légèrement augmenté pour le modèle encodé (0.5909) par rapport au modèle original (0.5623), indiquant une amélioration de 0.0285. Cela suggère une meilleure capacité du modèle à distinguer les classes positives et négatives malgré une précision globale légèrement inférieure."
      ],
      "id": "9c7d79e1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RESUME DES PERFORMANCES DES MODELES\n",
        "En résumé, l'utilisation de couches d'embeddings avec une moyenne pour le pooling n'a pas amélioré la précision globale (Accuracy), mais a permis une meilleure distinction entre les classes comme en témoigne l'amélioration du ROC AUC et un meilleur rappel pour la classe 'Sarcastic'. Cependant, cela s'est fait au prix d'une augmentation des faux positifs pour la classe 'Non-Sarcastic'. Le modèle est toujours loin d'être parfait, mais l'approche par embeddings montre un potentiel pour mieux capturer les nuances sémantiques."
      ],
      "metadata": {
        "id": "NI-2qH0llamV"
      },
      "id": "NI-2qH0llamV"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}